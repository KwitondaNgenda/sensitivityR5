---
title: " A Package to assess Rubin rules, perform sensitivity analysis using designmatch,Match and Matchit objects directly"
author: "David N."
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tidyr);library(ggplot2);library(designmatch);library(MatchIt);library(Matching)
```



#Introduction.

Over the past few decades, technology has made it easier for researchers to access variety of  observational data. Such data include information collected from patient medical records, national surveys et al. Availability of this data provides opportunities for exploring important research questions, however to do so one has be careful in designing studies based on these data. A common use of observation study is in estimating treatment effect. This typically involves defining a variable to measured exposure and then using it to identify a treatment and control group. Since the gold standard for estimating a treatment effect is to use data collected from a randomized clinical trial, observational data has to be preprocessed using observational study design algorithms to ensure data used to make treatment effect is as similar as possible to data that would have been obtained from a clinical trial. 

One of the assumptions made when estimating treatment effect from observational studies is what is called the the ignorabiltiy assumption,that is, only the observed covariates are sufficient to explain any meaningful differences between the treatment and control groups. The consequence of this assumption is that if the groups being compared are similar on average, on these observed covariates , then any differences in the outcome being studied is due to treatment- the only distinguishing factor between the groups being compared. The design phase of an observational study is usually focused on achieving the best possible balance of observed covariates between the treated and control group. Several design algorithms have been proposed and R packages that implement them are widely available.  The main steps during the design phase of an observational study are:

1. Determine variables that confounder the relationship between treatment and outcome
2. Using confounders in step 1, compute a metric (e.g propensity score) to be used to measure distance between any two observations
3. Match observation based on the metric in step 2
4. Assess balance of variables in step 1 across treatment and control group. If balance is poor repeat step 2-4.
5. Estimate the treatment effect in the preprocessed sample

In his 2008 paper , Stuart et al provides a detailed description of the major design algorithms and R packages that implement them. 

When designing an observation study, one usually has to run different matching algorithm and pick one that gives the best balance. With various matching algorithms housed in different R packages , for sometime , it was hard to compare across design methods. To easy this process, Greifer et al developed the `cobalt` package that interacts seamlessly  with objects from `Matching` and `MacthIt` packages and generate key balance summary statistics on.

The main critique of observational studies that use matched sampling design methods is that treatment effect estimates obtained are premised on the assumption that observed variables are sufficient to explain the differences between treated and control group. To deal with this criticism , Rosenbaum developed a sensitivity analysis framework that , if a significant treatment effect exists, computes a parameter to quantify a bias magnitude due to unmeasured confounders that would be required to nullify significant results. Presenting results of these sensitivity analysis allows the reader to make an informed decision on how much faith to place in your findings.

A significant portion of sensitivity methods developed by Rosenbaum has been implemented in the `rbounds`package (Keele,2008). However `rbounds` functions only interact with objects from the `Matching` package. The package does not also implement a sensitivity analysis method for time to event outcomes. To perform sensitivity analysis involving matched sets, Rosenbaum developed two packages `sensitivitymv` and `sensitivitymw`(Rosenbaum,2013). These two packages also provide more robust test statistic that increase the power of sensitivity. However, to perform sensitivity analysis using these packages require reshaping your data set to conform to a certain format.

It is important to note that this package does not replace the highly sophisticated matching and  sensitivity tools in the packages described above. What this package does is to bridge the most common matching packages to various sensitivity packages where such connections do not exist and would require more work on the part of the analyst.

# Why use this package ?

## Easy sensitivity analyisis when matched sampling is not necessary done with `Matching` package.
Our packages interacts seamlessly with objects from packages that implement matching methods not contained in the `Matching` package, specifically `MatchIt`(Ho et al 2007) and `designmatch`(Zubezarreta et al 2016). This package therefore gives the user the freedom to perform sensitivity analysis using output from any matching package. 


## Sensitivity analysis for matched sets from any package.
Unlike `rbounds` which implements sensitivity analysis for matched pairs only , this package contains functions which accept objects from various matching packages that produce matched sets. These functions will then ,simultaneously, transforms and performs sensitivity analysis using these objects. Using this package in this way can save significant time require to transform objects from various packages to create valid inputs for `sensitivitymv` or `sensitivitymw`, the two packages that perform sensitivity analysis for matched sets.

## Balance and Sensitivity Analysis Plots.
Most matching packages contain plots and tables useful in judging quality of matches obtained after matching, the most common being the love plot (Thomas Love). This package adds to these tools by providing sensitivity analysis and amplification plots(Rosenbaum ,2013) to help visualize and interpret findings.


# Using the package.

This package contains four main functions `rubinrules()`, `pens2()`, `binarysens2`, `t2event()` . Other auxilliary functions in the package include  `ampPlot()` and `eda()`. In the sections that follow , a detailed description of how each is used is given.

Currently this package is housed on github therefore to install it use the following code:



```{r packageinstall,message=FALSE}
library(devtools)
devtools::install_github("Ngendahimana/SensitivityR5")

```


## rubinRules

`rubinRules()` is a function that can be use to evaluate the three balance meusures suggested by Rubin (2001) and are based on the theory published in another paper by Rubin and Thomas (2006). Rubin Provides three guidelines to ensure that the results of regression adjustment - often conducted in the analysis phase of observational studies to clear any residual imbalances - are valid. The three guidelines are: 

+ Rule 1: The absolute standardized difference of means of the propensity score should be less than 0.25.
+ Rule 2: The ratio of the variances of the propensity score in the treated and control groups should be between 0.5 and 2
+ Rule 3: For each covariate, the ratio of the variance of the residuals orthogonal to the propensity score in the treated and control groups should be between 0.5 and 2.


An example of how to use the `rubinRules` function to assess these guidelines is illustrated below

```{r rubinRules,fig.width = 5, fig.asp =1,message=FALSE,warning=FALSE}

library(SensitivityR5)

data("toy",package = "SensitivityR5")
psmodel <- glm(treated ~ covA + covB + covC + covD + covE + covF + Asqr + BC + BD, family=binomial(), data=toy)
toy$ps <- psmodel$fitted
toy$linps <- psmodel$linear.predictors
covlist1=c('covA', 'covB', 'covC', 'covD', 'covE', 'covF.Middle', 'covF.High', 'Asqr','BC', 'BD')
k =rubinRules2(data=toy,Treatment='treated',covlist=covlist1)
k$plot

```

The first two Rubin balance meausures are displayed at the top of the plot while the third balance measure which consists of series of residual variance ratios for variable are displayed inside the dot plot. The blue lines indicate acceptable range for the residual variance ratios. Ratio outside region bounded by the red lines are considered unacceptable. This plot is a `ggplot` object and can be modified like any `ggplot` graph. For example to modify the plot title and background, the following code could be executed:


```{r modifyrubinRules,fig.width = 5, fig.asp =1,message=FALSE,warning=FALSE}
k$plot+theme_bw()+labs(title = "Assessing Rubin (2010) Balance Measures")
```

Various items can be called off of the list (k) using conventional R methods. For example to obtain a dataset of residual variance ratio , you can do the following.

```{r individualRubinComponents}
k$RUBIN3

```


## Love Plot

Although Love plot for assessing standardized balance measure for objects produced by `Matching ` and `MatchIt` has already been implemented in `Cobalt` package through the Love.plot function, this function cannot interact with `designmatch` object directly. On the other hand the love plot object currently implemented in  `designmatch` package is not a `ggplot` objects and therefore makes it hard to customize as desired. The Love plot function in this package allows you to generate ggplot Love figures using objects from any of the three matching packages including `designmatch` package.  

The code chunk below shows how to accomplish this.

### Using `designmatch` objects 

This example uses to design match which implements cardinality matching which balances variables directly rather than using a summary measure to quantify the distance between observations. This matching optimizes on the sample size rather than simply a distance measure like propensity score.

```{r cardinalityMatch,echo=FALSE,warning=FALSE,message=FALSE}

data("lalonde",package = "cobalt")
attach(lalonde)

## Treatment indicator
t_ind =lalonde$treat

## Distance matrix
dist_mat = NULL

## Subset matching weight.
subset_weight = 1

# Moment balance: constrain differences in means to be at most .05 standard deviations apart
mom_covs = cbind(age, educ, black ,hispan, married, nodegree, re74, re75)
mom_tols = round(absstddif(mom_covs, t_ind, .05), 2)
mom = list(covs = mom_covs, tols = mom_tols)

## Fine balance
fine_covs = cbind(black, hispan, married, nodegree)
fine = list(covs = fine_covs)

## Exact matching
#exact_covs = cbind(black)
#exact = list(covs = exact_covs)

## Solver options
t_max = 60*5
solver = "glpk"
approximate = 1
solver = list(name = solver, t_max = t_max, approximate = approximate,round_cplex = 0, trace = 0)

## Cardinality matching
out = bmatch(t_ind = t_ind, dist_mat = dist_mat, subset_weight = subset_weight, mom = mom, fine = fine,  solver = solver)

# Indices of the treated units and matched controls
t_id = out$t_id
c_id = out$c_id
detach(lalonde)

```

To assess balance with `love_plot` function in this package after cardinality matching you would need to execute the following code

```{r LoveplotDesignMatch,fig.width=6,fig.asp=1,message=FALSE,warning=FALSE}
p = love_plot(X =out, data = lalonde , covList=c("age", "educ", "black", "hispan", "married", "nodegree", "re74", "re75"))

p
```

Note that `out` is an object from the `designmatch` package that implements cardinality matching.

This plot can be enhanced using `ggplot2` features. For example we can add desired standardized difference threshhold lines  , say,  from -0.1 to 0.1 and remove the legend title with the following code: 

```{r modifyLoveplotDesignMatch,fig.width=6,fig.asp=1,warning=FALSE,message=FALSE}
p+theme_bw()+geom_vline(xintercept = -0.1)+ geom_vline(xintercept = 0.1) +theme(legend.title = element_blank())

```


Object from `MatchIt` and `Matching` packages can also be directly used with the `love_plot` function. You can also use the love plot function to extrac other important balance measures. We illustrate this using optimal matching functionality within the `MatchiIt`package. 

## Sensitivity Analysis.

As mentioned earlier, one of the aims of this package is to facilitate seamless transition between analysis of an observational study to perfoming sensitivity analysis. In the section that follow we illustrate how to use functions within this package to accomplish this task.

### `pens2` Function.
This function is meant to facilitate sensitivity analysis for continous outcomes. There is  a similar function in `rbounds` package that implements this method howevever rbounds interacts only with `Matching` package objects which impliments limited methods of matched sampling.

Using `lalonde` dataset , the code below illustrates how to do sensitivity analysis after implementing an optimal matching algorithm

```{r withMatchIt}

library(Matching);library(MatchIt)
data("lalonde",package = "Matching")

## Sensitivity analysis with a matchit object
m.out = matchit(treat ~ age  + educ +  black + hisp +married + nodegr + re74  + re75  +
u74 + u75, family=binomial, data = lalonde, method = "optimal")

## Estimating treatment effect. Ideally, balance assessement should be done prior to estimating treatment effect
mod = lm(re78~age  + educ +  black + hisp +married + nodegr + re74  + re75  +u74 + u75,data = match.data(m.out))

## Sensitivity analysis
sens.out =pens2(x = m.out, y="re78",Gamma = 2, GammaInc = 0.1,est = 629.7)

```

Note that when using `MatchIt` objects you have to specify the effect estimate or put -1 if there a negative effect estimate and 1 otherwise. After executing this code, you can access a table of sensitivity parameters and their respective Rosenbaum bounds by running the code below:.

```{r gammabounds}
sens.out$bounds
```

The other advantage of using this package is that it allows you to used objects processed by `designmatch` package to run sensitivity analysis. This especially important when one wants to implemented more sophisticated matching methods that are not available with either `MatchtIt` or `Matching` package such allowing for near fine matching or fine matching. For example run a sensitivity analysis using the design match object `out` created earlier on, the following code would be used:

```{r designCont,echo=FALSE}
data("lalonde",package = "designmatch")
library(designmatch)
attach(lalonde)
## Treatment indicator
t_ind = treatment
## Distance matrix
dist_mat = NULL
## Subset matching weight
subset_weight = 1
## Moment balance: constrain differences in means to be at most .05 standard deviations apart
mom_covs = cbind(age, education, black, hispanic, married, nodegree, re74, re75)
mom_tols = round(absstddif(mom_covs, t_ind, .05), 2)
mom = list(covs = mom_covs, tols = mom_tols)
## Fine balance
fine_covs = cbind(black, hispanic, married, nodegree)
fine = list(covs = fine_covs)
## Exact matching
exact_covs = cbind(black)
exact = list(covs = exact_covs)
## Solver options
t_max = 60*5
solver = "glpk"
approximate = 1
solver = list(name = solver, t_max = t_max, approximate = approximate,round_cplex = 0, trace = 0)
## Match
out = bmatch(t_ind = t_ind, dist_mat = dist_mat, subset_weight = subset_weight,mom = mom, fine = fine, exact = exact, solver = solver)
```



```{r sensitiivtyCard}
pens2(x = out, y="re78",Gamma = 2, GammaInc = 0.1,est = 234,treat = "treatment",data = lalonde)
detach(lalonde)
```



